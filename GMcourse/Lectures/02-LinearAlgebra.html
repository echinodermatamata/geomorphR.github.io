<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>2. Linear Algebra</title>
    <meta charset="utf-8" />
    <meta name="author" content="" />
    <script src="02-LinearAlgebra_files/header-attrs-2.19/header-attrs.js"></script>
    <script src="02-LinearAlgebra_files/htmlwidgets-1.6.1/htmlwidgets.js"></script>
    <link href="02-LinearAlgebra_files/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
    <script src="02-LinearAlgebra_files/datatables-binding-0.27/datatables.js"></script>
    <script src="02-LinearAlgebra_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <link href="02-LinearAlgebra_files/dt-core-1.12.1/css/jquery.dataTables.min.css" rel="stylesheet" />
    <link href="02-LinearAlgebra_files/dt-core-1.12.1/css/jquery.dataTables.extra.css" rel="stylesheet" />
    <script src="02-LinearAlgebra_files/dt-core-1.12.1/js/jquery.dataTables.min.js"></script>
    <link href="02-LinearAlgebra_files/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
    <script src="02-LinearAlgebra_files/crosstalk-1.2.0/js/crosstalk.min.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="utilities.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# 2. Linear Algebra
]
.subtitle[
## AKA: The important foundation for everything that follows!
]
.author[
### 
]

---




### Linear Algebra: Goals

Understand why this equation is a foundational equation used in geometric morphometrics (GM) 

`$$\small\mathbf{Z}=[tr[\mathbf{(Y-\overline{Y})(Y-\overline{Y})^T}]]^{-1/2}\mathbf{(Y-\overline{Y})H}$$`
---

### Linear Algebra: Goals

Understand why this equation is a foundational equation used in geometric morphometrics (GM) 

`$$\small\mathbf{Z}=[tr[\mathbf{(Y-\overline{Y})(Y-\overline{Y})^T}]]^{-1/2}\mathbf{(Y-\overline{Y})H}$$`


Understand why this equation is a foundational equation in multivariate statistics (and burn it into your memory)

`$$\hat{\mathbf{B}}=\left ( \mathbf{\tilde{X}}^{T} \mathbf{\tilde{X}}\right )^{-1}\left ( \mathbf{\tilde{X}}^{T} \mathbf{\tilde{Y}}\right )$$`
---

### Linear Algebra: Goals

Understand why this equation is a foundational equation used in geometric morphometrics (GM) 

`$$\small\mathbf{Z}=[tr[\mathbf{(Y-\overline{Y})(Y-\overline{Y})^T}]]^{-1/2}\mathbf{(Y-\overline{Y})H}$$`


Understand why this equation is a foundational equation in multivariate statistics (and burn it into your memory)

`$$\hat{\mathbf{B}}=\left ( \mathbf{\tilde{X}}^{T} \mathbf{\tilde{X}}\right )^{-1}\left ( \mathbf{\tilde{X}}^{T} \mathbf{\tilde{Y}}\right )$$`

Understand why this equation is a universal equation for describing the alignment of shape data (or any multivariate data) to an alternative set of data, covariance structure, or model

`$$\mathbf{A}^T\mathbf{Z} =\mathbf{UDV}^T$$`
---

### Overview:
- Scalars and Vectors
- Vector addition and subtraction
- Vector multiplication
- Matrices (collections of vectors)
- Special Matrices
- Matrix inversion
- Special Matrix Properties
- General Linear Model Preview
- Sums of Squares and Cross-products
- Covariance matrices
- Decompositions
- Summary
---

.center[

# Part I. Basics

## (vector and matrix operations)

]
---




### Scalars and Vectors

Scalars
 
`$$a = 5$$`   `$$b = 2$$`   `$$c = -3$$`

Vectors
 
`$$\mathbf{a} = \begin{bmatrix}
 5 \\ 
 3 \\ 
 -2 
\end{bmatrix}$$`

`$$\mathbf{a}^T = \begin{bmatrix}
 5 &amp; 3 &amp; -2
\end{bmatrix}$$`

The superscript, `\(^T\)`, means vector transpose.  Note, `\(\left(\mathbf{a}^T \right)^T = \mathbf{a}\)`

---
### Scalars and Vectors (cont.)

Vector addition/subtraction (consistent orientation is important)

`$$\mathbf{b}^T = \begin{bmatrix}
 -5 &amp; 0 &amp; 1
\end{bmatrix}$$`

`$$\mathbf{a}^T + \mathbf{b}^T= \begin{bmatrix}
 0 &amp; 3 &amp; -1
\end{bmatrix}$$`

`$$\mathbf{a} - \mathbf{b} = \begin{bmatrix}
 10 \\ 3 \\ -3
\end{bmatrix}$$`

---
### Vector Multiplication

#### Not this!

`$$\mathbf{a}^T = \begin{bmatrix}
 5 &amp; 3 &amp; -2
\end{bmatrix}$$`

`$$\mathbf{b}^T = \begin{bmatrix}
 -5 &amp; 0 &amp; 1
\end{bmatrix}$$`

`$$\mathbf{a}^T \times \mathbf{b}^T= \begin{bmatrix}
 -25 &amp; 0 &amp; -2
\end{bmatrix}$$`

But it is kind of that, in part...

---

### Vector Multiplication (cont.)

Vector multiplication is both multiplication and summation of scalars.  Before performing vector multiplication, there has to be consistency with **inner dimensions**.

- Dimensions `\(\mathbf{a}: 3 \times 1\)`

- Dimensions `\(\mathbf{a}^T: 1 \times 3\)`

- Dimensions `\(\mathbf{b}: 3 \times 1\)`

- Dimensions `\(\mathbf{b}^T: 1 \times 3\)`

For any vector product, arrange the dimensions for the attempted product and see if inner dimensions match; e.g., 
`$$\mathbf{a} \times \mathbf{b}: 3 \times \color{blue} {1 \times 3} \times 1$$`
Does not match, so this product is not possible

---

### Vector Multiplication (cont.)

Vector multiplication is both multiplication and summation of scalars.  Before performing vector multiplication, there has to be consistency with **inner dimensions**.

- Dimensions `\(\mathbf{a}: 3 \times 1\)`

- Dimensions `\(\mathbf{a}^T: 1 \times 3\)`

- Dimensions `\(\mathbf{b}: 3 \times 1\)`

- Dimensions `\(\mathbf{b}^T: 1 \times 3\)`

For any vector product, arrange the dimensions for the attempted product and see if inner dimensions match; e.g., 
`$$\mathbf{a}^T \times \mathbf{b}: 1 \times \color{blue} {3 \times 3} \times 1$$`
**This matches!** Multiplication is possible.

---
### Vector Multiplication (cont.): Vector Inner-products

If inner dimensions match, the multiplication is possible.  The product has dimensions equal to the outer dimensions of the match.  There are two types of products:

- Inner-product: the vector product results is a single scalar, i.e., the outer dimensions are `\(1 \times 1\)`

- Outer-product: the vector product results in a series of scalar products with number and arrangement defined by outer dimensions
---

### Vector Multiplication (cont.): Vector Inner-products  (cont.)

#### Vector Inner-Product

For `\(n \times 1\)` vectors

`$$\mathbf{a}^T \mathbf{b} = \sum_{i=1}^n a_ib_i$$`

For example, 
`$$\mathbf{a}^T = \begin{bmatrix}
 5 &amp; 3 &amp; -2
\end{bmatrix}$$`

`$$\mathbf{b} = \begin{bmatrix}
 -5 \\ 0 \\ 1
\end{bmatrix}$$`

`$$\mathbf{a}^T \mathbf{b} = \left(5\times -5 \right) + \left(3 \times 0 \right) + \left(-2 \times 1 \right) = -27$$`

###### *Helpful mnemonic: "Run Amok Computational Demon!" for row-accross and column-down pattern (will be helpful for matrices)*
---
### Vector Multiplication (cont.): Vector Outer Products

If inner dimensions match, the multiplication is possible.  The product has dimensions equal to the outer dimensions of the match.  There are two types of products:

- Inner-product: the vector product results is a single scalar, i.e., the outer dimensions are `\(1 \times 1\)`

- Outer-product: the vector product results in a series of scalar products with number and arrangement defined by outer dimensions
---
#### Vector Outer-Product

For `\(n \times 1\)` vectors

`$$\mathbf{a}\mathbf{b}^T  = \begin{bmatrix}
a_1b_1 &amp; a_1b_2 &amp; a_1b_3 &amp; \cdots &amp; a_1b_n\\
a_2b_1 &amp; a_2b_2 &amp; a_2b_3 &amp; \cdots &amp; a_2b_n\\
a_3b_1 &amp; a_3b_2 &amp; a_3b_3 &amp; \cdots &amp; a_3b_n\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
a_nb_1 &amp; a_nb_2 &amp; a_nb_3 &amp; \cdots &amp; a_nb_n\\
\end{bmatrix} =
\mathbf{M}_{n \times n}$$`
---
### Vector Multiplication (cont.): Vector Outer Products (cont.)

### Important Notes

`$$\mathbf{a}\mathbf{b}^T  = \begin{bmatrix}
a_1b_1 &amp; a_1b_2 &amp; a_1b_3 &amp; \cdots &amp; a_1b_n\\
a_2b_1 &amp; a_2b_2 &amp; a_2b_3 &amp; \cdots &amp; a_2b_n\\
a_3b_1 &amp; a_3b_2 &amp; a_3b_3 &amp; \cdots &amp; a_3b_n\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
a_nb_1 &amp; a_nb_2 &amp; a_nb_3 &amp; \cdots &amp; a_nb_n\\
\end{bmatrix} =
\mathbf{M}_{n \times n}$$`

- `\(\mathbf{M}\)` is called a matrix, with dimensions defined
- `\(\mathbf{M}\)` comprises row vectors and column vectors
- because `\(\mathbf{M}\)` has the same number of rows and columns, it also has a diagonal vector
- the sum of the diagonal vector, called the **trace**, is the inner-product of `\(\mathbf{a}\)` and `\(\mathbf{b}\)`
---


### Matrices
A matrix is more than a vector outer-product (more precisely, a vector outer-product is merely one type of matrix).  A matrix is a collection of vectors, arranged in a specific way, such that linear algebra operations can be carried, systematically.  For example, the arrangement of vectors in a matrix indicates how to find a series of inner-products and display their results.

The most basic matrices for statistics are **data frames**.  In data frames, column vectors are variables and row vectors are observations.  We can demonstrate this easily in `R` with the `data.frame` and `matrix` functions.


```
##       y1 y2
## obs.1  2 -1
## obs.2  3 -2
## obs.3  2  0
## obs.4  5  0
## obs.5  6  1
## obs.6  8 -1
```
---

### Matrices (Cont.)



```
##       y1 y2
## obs.1  2 -1
## obs.2  3 -2
## obs.3  2  0
## obs.4  5  0
## obs.5  6  1
## obs.6  8 -1
```
Which is R's way of saying,

`$$\small{\mathbf{Y} = \begin{bmatrix}
2 &amp; -1 \\
3 &amp; -2 \\
2 &amp; 0 \\
5 &amp; 0 \\
6 &amp; 1 \\
8 &amp; -1 \\
\end{bmatrix}}$$`

`\(\mathbf{Y}\)` is a matrix and a data frame.  Row vectors are observations for the variables represented as column vectors. The dimensions of `\(\mathbf{Y}\)` are `\(n \times p\)` for the `\(n\)` observations of subjects for `\(p\)` variables.
---

### Matrices (Cont.)

#### This time with additional `R` code

```r
y1 &lt;- c(2, 3, 2, 5, 6, 8) # variable 1 with 6 observations
y2 &lt;- c(-1, -2, 0, 0, 1, -1) # variable 2 with 6 observations
*Y &lt;- data.frame(y1 = y1, y2 = y2)
rownames (Y) &lt;- paste("obs", 1:6, sep = ".") # giving our observations some names
Y
```

```
##       y1 y2
## obs.1  2 -1
## obs.2  3 -2
## obs.3  2  0
## obs.4  5  0
## obs.5  6  1
## obs.6  8 -1
```
---

### Matrix Addition, Subtraction, Multiplication

#### Matrix addition and subtraction
Matrix addition and subtraction is no different than vector addition and subtraction.  Matrices have to have *commensurate* dimensions (same `\(n \times p\)`).

#### Matrix multiplication
Matrix multiplication is nothing more than systematic calculation of vector inner-products and arrangement of these into precise corresponding elements of a new matrix.  Like vectors, inner dimensions must match and the product is defined by the outer dimensions.  The simplest way to define this is as follows

Let `\(\mathbf{X}\)` be an `\(n \times k\)` matrix and let `\(\mathbf{Y}\)` by an `\(n \times p\)` matrix, such that

`$$\mathbf{X} = \begin{bmatrix}
\mathbf{x}_1 &amp;
\mathbf{x}_2 &amp;
\cdots &amp;
\mathbf{x}_k 
\end{bmatrix}$$`

and

`$$\mathbf{Y} = \begin{bmatrix}
\mathbf{y}_1 &amp;
\mathbf{y}_2 &amp;
\cdots &amp; 
\mathbf{y}_p
\end{bmatrix}$$`

Note that each `\(\mathbf{x}_i\)` column vector is `\(n \times 1\)` in dimension for `\(k\)` vectors and each `\(\mathbf{y}_i\)` is `\(n \times 1\)` in dimension for `\(p\)` vectors.  Thus,
---
### Matrix Addition, Subtraction, Multiplication (Cont.)

`$$\mathbf{X} = \begin{bmatrix}
\mathbf{x}_1 &amp;
\mathbf{x}_2 &amp;
\cdots &amp;
\mathbf{x}_k 
\end{bmatrix}$$`

and 

`$$\mathbf{Y} = \begin{bmatrix}
\mathbf{y}_1 &amp;
\mathbf{y}_2 &amp;
\cdots &amp; 
\mathbf{y}_p
\end{bmatrix}$$`

and 

`$$\mathbf{X}^T\mathbf{Y} = \begin{bmatrix}
\mathbf{x}_1^T\mathbf{y}_1 &amp; \mathbf{x}_1^T\mathbf{y}_2 &amp; \cdots &amp; \mathbf{x}_1^T\mathbf{y}_p\\
\mathbf{x}_2^T\mathbf{y}_1 &amp; \mathbf{x}_2^T\mathbf{y}_2 &amp; \cdots &amp; \mathbf{x}_2^T\mathbf{y}_p\\
\vdots &amp; \vdots &amp; &amp; \vdots\\
\mathbf{x}_k^T\mathbf{y}_1 &amp; \mathbf{x}_k^T\mathbf{y}_2 &amp; \cdots &amp; \mathbf{x}_k^T\mathbf{y}_p\\
\end{bmatrix}$$`

The matrix product is a matrix with `\(k \times p\)` inner-products
---
### Matrix Multiplication (Cont.)

#### Matrix multiplication example (using R script)




```r
n &lt;- 50
p &lt;- 3
y1 &lt;- rnorm(50) # variable y1 with 50 observations
y2 &lt;- rnorm(50) # variable y2 with 50 observations
y3 &lt;- rnorm(50) # variable y2 with 50 observations
Y &lt;- as.matrix(data.frame(y1 = y1, y2 = y2, y3 = y3))
rownames (Y) &lt;- paste("obs", 1:n, sep = ".") # giving our observations some names
dim(Y)
```

```
## [1] 50  3
```

---

### Matrix Multiplication (Cont.)

#### Example data frame, `\(\mathbf{Y}\)`

<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-1a648e86760617d8a29a" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-1a648e86760617d8a29a">{"x":{"filter":"none","vertical":false,"fillContainer":false,"data":[["obs.1","obs.2","obs.3","obs.4","obs.5","obs.6","obs.7","obs.8","obs.9","obs.10","obs.11","obs.12","obs.13","obs.14","obs.15","obs.16","obs.17","obs.18","obs.19","obs.20","obs.21","obs.22","obs.23","obs.24","obs.25","obs.26","obs.27","obs.28","obs.29","obs.30","obs.31","obs.32","obs.33","obs.34","obs.35","obs.36","obs.37","obs.38","obs.39","obs.40","obs.41","obs.42","obs.43","obs.44","obs.45","obs.46","obs.47","obs.48","obs.49","obs.50"],[1.4172,-0.7282,-0.2667,1.0735,0.723,-1.3032,0.762,1.3157,0.1616,0.5382,-1.125,-0.9247,-0.3069,0.8774,0.7183,-1.1153,-1.459,0.3562,0.1912,-0.3329,0.2793,-0.8332,2.4215,-0.6904,-0.4653,-0.0098,0.1828,0.933,0.2655,-1.067,0.327,1.0057,0.8276,0.7262,1.0841,-1.3492,0.8317,1.4915,-0.3591,0.1575,0.0182,-1.1856,-1.2937,0.6164,0.8237,0.0788,1.17,0.0369,1.1106,-1.4118],[0.7752,0.7821,1.0205,-1.6889,0.0354,-0.8363,0.2619,1.4614,-1.0031,-0.5509,-0.1107,-1.1232,-0.5396,1.3207,1.732,0.0168,-0.3069,-2.4835,1.3488,-0.0394,0.7086,-0.2577,-1.0495,-1.2812,-0.4344,-0.1469,0.8479,0.6678,-1.2007,0.5141,0.4316,-0.4485,-0.5182,-1.6906,-0.1333,1.1896,-0.3844,0.3085,0.3534,-0.2103,0.1276,0.6246,2.2465,-0.9144,-0.1832,0.0494,-1.1033,0.5866,0.4888,1.4424],[-0.0913,-0.3958,0.8213,-0.5844,-1.1732,0.124,-0.1117,0.3667,1.8759,-1.0421,1.5979,0.8733,-1.3501,-0.6104,1.0627,0.1467,-0.7203,-0.5828,-0.2574,-0.8376,-0.8407,-0.1998,-0.2236,-0.0224,-0.2883,1.6402,-0.2349,-1.0472,0.5142,-0.9789,1.8749,0.7681,0.736,0.4188,1.14,-0.9332,-1.5754,-0.7969,-1.3347,-0.5171,-0.6405,-0.2055,1.197,0.8096,1.4685,0.0188,-0.8426,0.3668,-0.9631,1.9462]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>y1<\/th>\n      <th>y2<\/th>\n      <th>y3<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":8,"columnDefs":[{"className":"dt-right","targets":[1,2,3]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[8,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>
---

### Matrix Multiplication (Cont.)

#### Matrix multiplication example (using R script)


```r
X &lt;- cbind(Intercept = rep(1, n), group = rep(c(0, 1), n / 2))
rownames(X) &lt;- rownames(Y)
```
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-3f68752ae0db151dfa62" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-3f68752ae0db151dfa62">{"x":{"filter":"none","vertical":false,"fillContainer":false,"data":[["obs.1","obs.2","obs.3","obs.4","obs.5","obs.6","obs.7","obs.8","obs.9","obs.10","obs.11","obs.12","obs.13","obs.14","obs.15","obs.16","obs.17","obs.18","obs.19","obs.20","obs.21","obs.22","obs.23","obs.24","obs.25","obs.26","obs.27","obs.28","obs.29","obs.30","obs.31","obs.32","obs.33","obs.34","obs.35","obs.36","obs.37","obs.38","obs.39","obs.40","obs.41","obs.42","obs.43","obs.44","obs.45","obs.46","obs.47","obs.48","obs.49","obs.50"],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Intercept<\/th>\n      <th>group<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":6,"columnDefs":[{"className":"dt-right","targets":[1,2]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[6,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>

---

### Matrix Multiplication (Cont.)

#### Matrix multiplication example (using R script)


```r
t(X) %*% Y
```

```
##                  y1         y2         y3
## Intercept  6.295172  0.7029465  0.3656386
## group     -1.744153 -2.7077558 -1.2747868
```

```r
crossprod(X, Y)
```

```
##                  y1         y2         y3
## Intercept  6.295172  0.7029465  0.3656386
## group     -1.744153 -2.7077558 -1.2747868
```

+ Notice that the row names are the column names of `\(\mathbf{X}\)` and the column names are the column names of `\(\mathbf{Y}\)`.  
+ Also notice the `crossprod` function is short for *matrix of cross-products*, which we will refer to simply as the **matrix cross-product**.  This is a bit unfortunate nomenclature, as the meaning is different than *vector cross-product*, a vector produced by multiplication in a certain way of two vectors, different from the *dot-product*, which is basically the same as the inner-product.  (Try not to let the terminology get to you!)
---


### ~~Matrix Division~~
This is not something we can do.  We can invert some matrices, but we will come back to this in a moment.

### Important Matrix and Vector Multiplication Properties
&gt;- Any matrix or vector multiplied by a scalar multiplies every element by the scalar.  The name, "scalar," means that every element is scaled.
&gt;- Like vectors that have inner-products (dot products) or outer-products, sometimes matrices can be similar.  The tendency though is to call these cross-product matrices.  
&gt;- A vector inner-product of the form, `\(\mathbf{x}^T\mathbf{x}\)` is a generalized method of squaring.  It is precisely the sum of squared values, rather than just a squared value.
&gt;- A matrix cross-product of the form, `\(\mathbf{X}^T\mathbf{X}\)` is a generalized method of squaring.  This matrix has summed squared values of column vectors of `\(\mathbf{X}\)` on a diagonal vector and summed cross-products between vectors in the off-diagonal elements.
&gt;- A matrix is **square** when it has equal rows and columns, e.g., `\(n \times n\)`.
&gt;- If `\(\mathbf{XY}\)` is possible and `\(\mathbf{YX}\)` is possible, they will not have the same product unless both matrices are square and `\(\mathbf{X} = \mathbf{Y}\)`.  The dimensions of matrix products are also likely different.
&gt;- The next slide will describe some special matrices.

.center[

# Part II. Special Matrices

## (Orthogonal, )

]
---

### Special Matrices

&lt;img src="LectureData/02.matrices/special.matrices.png" width="50%" style="display: block; margin: auto;" /&gt;

Orthogonal vectors or matrices with vectors that are also unit length, `\(\left( \mathbf{a}^T\mathbf{a}\right)^{1/2} = 1\)`, are also **orthonormal**.
---

### Special Matrices

| Matrix and description | Example | Comments |
| ------ | ---- | ------ |
|**Square matrix** Any matrix with the same number of rows and columns, e.g., `\(n \times n\)` | `\(\small{\mathbf{S} = \begin{bmatrix} 2 &amp; 3 &amp; 1 \\ 4 &amp; 7 &amp; 5\\ 1 &amp; 10 &amp; 0 \\ \end{bmatrix}}\)` | These matrices, themselves, are generally not too compelling, unless there is a relationship between the row and column variables.|
|**Symmetric matrix** A square matrix that has symmetry above and below the diagonal| `\(\small{\mathbf{S} = \begin{bmatrix} 2 &amp; 3 &amp; 1 \\ 3 &amp; 7 &amp; 10\\ 1 &amp; 10 &amp; 0 \\ \end{bmatrix}}\)` | These matrices have the condition that `\(\mathbf{S} = \mathbf{S}^T\)`.|


Orthogonal vectors or matrices with vectors that are also unit length, `\(\left( \mathbf{a}^T\mathbf{a}\right)^{1/2} = 1\)`, are also **orthornormal**.
---

### Special Matrices and Special Matrix Properties

#### Some additional notes
- Some sources refer to "triangular" matrices.  These might be symmetric matrices, where the elements above a diagonal match the elements below.  However, these might refer to a matrix that looks like a symmetric matrix but values below the diagonal are all 0.
- A matrix cross-product will always produce a symmetric matrix.

#### Special Matrix Properties (Really important at times!)
- **Symmetry**: `\(\mathbf{X} = \mathbf{X}^T\)`
- **Positive-definite**: If `\(\mathbf{X}\)` is symmetric, `\(\mathbf{a}^T \mathbf{Xa}\)` is a positive scalar if `\(\mathbf{a}\)` has non-zero values.  It also means all eigenvalues of `\(\mathbf{X}\)` are non-negative (more later).
- **Idempotent**: If `\(\mathbf{X}\)` is square, `\(\mathbf{XX} = \mathbf{X}\)`.
---
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "solarized-light",
"highlightLines": true,
"countIncrementalSlides": true,
"ratio": "16:9",
"self_contained": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
